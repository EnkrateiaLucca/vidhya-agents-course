{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- **Attention Mechanism**: Transformers use a method called \"attention\" to focus on different parts of the input data (like words in a sentence) based on their relevance, allowing the model to understand context and relationships better.\n",
       "\n",
       "- **Layers and Encoders/Decoders**: They consist of multiple layers, with each layer containing encoders and decoders. Encoders process the input data, while decoders generate the output, enabling tasks like translation or text generation.\n",
       "\n",
       "- **Parallel Processing**: Unlike older models that process data sequentially, transformers can handle multiple pieces of information at once. This makes them faster and more efficient, especially for large datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a research assistant'),\n",
    "    ('human', '{input}')\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "basic_chain = prompt | llm | output_parser\n",
    "\n",
    "output = basic_chain.invoke({'input': 'Write a 3 bullet point summary about how transformers work. Simplify to non-technical people but keep the main bits of information.'})\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a draft of a research report using chains in langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_SYS_MSG = \"\"\"\n",
    "You are a research assistant and a scientific writer.\n",
    "You take in requests about tpics and write organized research reprts on those topics.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', WRITER_SYS_MSG),\n",
    "    ('human', 'Write an organized research report about this topic:\\n\\n{topic}.')\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "writer_chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Understanding Transformers: A Non-AI Researcher’s Guide\n",
       "\n",
       "## Introduction\n",
       "Transformers are a type of model architecture that has revolutionized the field of artificial intelligence (AI), particularly in natural language processing (NLP). They have enabled significant advancements in tasks such as translation, text generation, and sentiment analysis. This report aims to explain the fundamental concepts of transformers in a way that is accessible to non-AI researchers.\n",
       "\n",
       "## 1. Background: The Need for Transformers\n",
       "Before transformers, traditional models for processing sequential data, like recurrent neural networks (RNNs), faced challenges such as difficulty in capturing long-range dependencies and slow training times. Transformers were introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017, addressing these limitations and providing a more efficient way to handle sequential data.\n",
       "\n",
       "## 2. Key Components of Transformers\n",
       "Transformers consist of several key components that work together to process data effectively:\n",
       "\n",
       "### 2.1. Input Representation\n",
       "Transformers take input data, such as sentences, and convert them into numerical representations called embeddings. Each word in a sentence is transformed into a vector, which captures its meaning in a high-dimensional space.\n",
       "\n",
       "### 2.2. Attention Mechanism\n",
       "The attention mechanism is the core innovation of transformers. It allows the model to weigh the importance of different words in a sentence when making predictions. For example, in the sentence \"The cat sat on the mat,\" the model can focus on the word \"cat\" when predicting the next word after \"The.\"\n",
       "\n",
       "#### 2.2.1. Self-Attention\n",
       "Self-attention is a specific type of attention used within transformers. It enables the model to consider all words in a sentence simultaneously, allowing it to understand context better. Each word can attend to every other word, creating a rich representation of the sentence.\n",
       "\n",
       "### 2.3. Multi-Head Attention\n",
       "Transformers use multiple attention heads to capture different aspects of the relationships between words. Each head learns to focus on different parts of the input, providing a more comprehensive understanding of the data.\n",
       "\n",
       "### 2.4. Feedforward Neural Networks\n",
       "After the attention mechanism, the output is passed through feedforward neural networks, which apply additional transformations to the data. This step helps in refining the representations learned from the attention mechanism.\n",
       "\n",
       "### 2.5. Positional Encoding\n",
       "Since transformers do not process data sequentially like RNNs, they require a way to understand the order of words. Positional encoding is added to the input embeddings to provide information about the position of each word in the sentence.\n",
       "\n",
       "## 3. Structure of a Transformer\n",
       "A transformer model is typically composed of an encoder and a decoder:\n",
       "\n",
       "### 3.1. Encoder\n",
       "The encoder processes the input data and generates a set of representations. It consists of multiple layers, each containing multi-head attention and feedforward neural networks. The output of the encoder is a set of vectors that encapsulate the meaning of the input.\n",
       "\n",
       "### 3.2. Decoder\n",
       "The decoder takes the encoder's output and generates the final output, such as a translated sentence. It also consists of multiple layers and includes an additional attention mechanism that allows it to focus on the encoder's output while generating each word.\n",
       "\n",
       "## 4. Training Transformers\n",
       "Transformers are trained using large datasets and a process called supervised learning. During training, the model learns to predict the next word in a sentence based on the previous words. This is done by minimizing the difference between the predicted and actual words, adjusting the model's parameters to improve accuracy.\n",
       "\n",
       "## 5. Applications of Transformers\n",
       "Transformers have a wide range of applications beyond NLP, including:\n",
       "\n",
       "- **Machine Translation**: Translating text from one language to another.\n",
       "- **Text Summarization**: Condensing long articles into shorter summaries.\n",
       "- **Sentiment Analysis**: Determining the sentiment expressed in a piece of text.\n",
       "- **Image Processing**: Adapting transformer architecture for tasks in computer vision.\n",
       "\n",
       "## Conclusion\n",
       "Transformers represent a significant advancement in AI, particularly in how we process and understand language. By leveraging the attention mechanism and a structured architecture, transformers can capture complex relationships in data, making them powerful tools for various applications. Understanding the basics of transformers can provide valuable insights into the ongoing developments in AI and its potential impact on various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = writer_chain.invoke({'topic': 'How do transformers work for non AI researchers?'})\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Feedback on \"Understanding Transformers: A Non-AI Researcher’s Guide\"\n",
       "\n",
       "1. **Clarity and Accessibility**: The report does an excellent job of breaking down complex concepts into understandable segments for non-AI researchers. The use of simple language and clear explanations, particularly in sections like \"Key Components of Transformers,\" makes the material accessible.\n",
       "\n",
       "2. **Logical Structure**: The organization of the report is logical and flows well from the introduction to the conclusion. Each section builds on the previous one, which helps in reinforcing understanding. However, consider adding a brief overview or roadmap at the end of the introduction to outline what readers can expect in each section.\n",
       "\n",
       "3. **Examples and Analogies**: While the report includes some examples (e.g., the sentence \"The cat sat on the mat\"), it could benefit from more real-world analogies or scenarios that illustrate how transformers are used in practice. This would help non-AI researchers relate the concepts to familiar contexts.\n",
       "\n",
       "4. **Visual Aids**: The report would be enhanced by the inclusion of diagrams or visual representations of the transformer architecture, attention mechanisms, and the encoder-decoder structure. Visual aids can significantly aid comprehension, especially for complex topics.\n",
       "\n",
       "5. **Future Directions and Limitations**: While the report effectively covers the fundamentals and applications of transformers, it could be improved by discussing current limitations and future directions in transformer research. This would provide a more balanced view and encourage readers to think critically about the technology's implications and potential challenges."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REVIEWER_SYS_MSG = \"\"\"\n",
    "You are a reviewer for research reports. You take in research reports and provide feecback on them.\n",
    "\"\"\"\n",
    "\n",
    "prompt_reviewer = ChatPromptTemplate.from_messages([\n",
    "    ('system', REVIEWER_SYS_MSG),\n",
    "    ('human', 'Provide feedback on this research report:\\n\\n{report}. As 5 concise bullet points.')\n",
    "])\n",
    "\n",
    "llm_reviewer = ChatOpenAI(model='gpt-4o-mini', temperature=0.2)\n",
    "\n",
    "review_chain = prompt_reviewer | llm_reviewer | output_parser\n",
    "\n",
    "feedback_output = review_chain.invoke({'report': output})\n",
    "\n",
    "Markdown(feedback_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Understanding Transformers: A Non-AI Researcher’s Guide\n",
       "\n",
       "## Introduction\n",
       "Transformers are a groundbreaking model architecture that has transformed the landscape of artificial intelligence (AI), particularly in the realm of natural language processing (NLP). They have facilitated remarkable advancements in tasks such as translation, text generation, and sentiment analysis. This report aims to elucidate the fundamental concepts of transformers in an accessible manner for non-AI researchers. \n",
       "\n",
       "To guide readers through the content, this report will cover the background and necessity of transformers, their key components, structural design, training methods, applications, and a discussion on their limitations and future directions.\n",
       "\n",
       "## 1. Background: The Need for Transformers\n",
       "Prior to the advent of transformers, traditional models for processing sequential data, such as recurrent neural networks (RNNs), encountered significant challenges. These included difficulties in capturing long-range dependencies and slow training times. The introduction of transformers in the seminal paper \"Attention is All You Need\" by Vaswani et al. in 2017 addressed these limitations, providing a more efficient and effective approach to handling sequential data.\n",
       "\n",
       "## 2. Key Components of Transformers\n",
       "Transformers are composed of several key components that work synergistically to process data effectively:\n",
       "\n",
       "### 2.1. Input Representation\n",
       "Transformers convert input data, such as sentences, into numerical representations known as embeddings. Each word in a sentence is transformed into a vector, capturing its meaning in a high-dimensional space.\n",
       "\n",
       "### 2.2. Attention Mechanism\n",
       "The attention mechanism is the core innovation of transformers. It enables the model to weigh the importance of different words in a sentence when making predictions. For instance, in the sentence \"The cat sat on the mat,\" the model can focus on the word \"cat\" when predicting the next word after \"The.\"\n",
       "\n",
       "#### 2.2.1. Self-Attention\n",
       "Self-attention is a specific type of attention utilized within transformers. It allows the model to consider all words in a sentence simultaneously, enhancing its understanding of context. Each word can attend to every other word, creating a rich representation of the sentence.\n",
       "\n",
       "### 2.3. Multi-Head Attention\n",
       "Transformers employ multiple attention heads to capture various aspects of the relationships between words. Each head learns to focus on different parts of the input, providing a more comprehensive understanding of the data.\n",
       "\n",
       "### 2.4. Feedforward Neural Networks\n",
       "Following the attention mechanism, the output is processed through feedforward neural networks, which apply additional transformations to the data. This step refines the representations learned from the attention mechanism.\n",
       "\n",
       "### 2.5. Positional Encoding\n",
       "Since transformers do not process data sequentially like RNNs, they require a method to understand the order of words. Positional encoding is added to the input embeddings to convey information about the position of each word in the sentence.\n",
       "\n",
       "## 3. Structure of a Transformer\n",
       "A transformer model typically consists of an encoder and a decoder:\n",
       "\n",
       "### 3.1. Encoder\n",
       "The encoder processes the input data and generates a set of representations. It comprises multiple layers, each containing multi-head attention and feedforward neural networks. The output of the encoder is a set of vectors that encapsulate the meaning of the input.\n",
       "\n",
       "### 3.2. Decoder\n",
       "The decoder takes the encoder's output and generates the final output, such as a translated sentence. It also consists of multiple layers and includes an additional attention mechanism that allows it to focus on the encoder's output while generating each word.\n",
       "\n",
       "## 4. Training Transformers\n",
       "Transformers are trained using large datasets through a process called supervised learning. During training, the model learns to predict the next word in a sentence based on the preceding words. This is achieved by minimizing the difference between the predicted and actual words, adjusting the model's parameters to enhance accuracy.\n",
       "\n",
       "## 5. Applications of Transformers\n",
       "Transformers have a wide array of applications beyond NLP, including:\n",
       "\n",
       "- **Machine Translation**: Translating text from one language to another.\n",
       "- **Text Summarization**: Condensing lengthy articles into concise summaries.\n",
       "- **Sentiment Analysis**: Assessing the sentiment expressed in a piece of text.\n",
       "- **Image Processing**: Adapting transformer architecture for tasks in computer vision.\n",
       "\n",
       "## 6. Limitations and Future Directions\n",
       "While transformers have significantly advanced AI, they are not without limitations. For instance, they require substantial computational resources and large datasets for training, which can be a barrier for smaller organizations. Additionally, transformers can struggle with tasks that require deep reasoning or understanding of complex relationships beyond surface-level patterns.\n",
       "\n",
       "Future research directions may focus on improving the efficiency of transformers, reducing their resource requirements, and enhancing their ability to understand context and reasoning. Exploring hybrid models that combine transformers with other architectures may also yield promising results.\n",
       "\n",
       "## Conclusion\n",
       "Transformers represent a significant advancement in AI, particularly in how we process and understand language. By leveraging the attention mechanism and a structured architecture, transformers can capture complex relationships in data, making them powerful tools for various applications. Understanding the basics of transformers provides valuable insights into ongoing developments in AI and its potential impact across diverse fields. \n",
       "\n",
       "Incorporating real-world analogies and visual aids can further enhance comprehension, making the concepts even more relatable and easier to grasp for non-AI researchers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_WRITER_SYS_MSG = \"\"\"\n",
    "You take in a research report and a set of bullet points with feedback to improve,\n",
    "and you revise the research report based on the feedback and write a final version.\n",
    "\"\"\"\n",
    "\n",
    "prompt_final_writer = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', FINAL_WRITER_SYS_MSG),\n",
    "        ('human', 'Write a reviewed and improved version of this research report:\\n\\n{report}, based on this feedback:\\n\\n{feedback}.')\n",
    "    ]\n",
    ")\n",
    "llm_final_writer = ChatOpenAI(model='gpt-4o-mini', temperature=0.2)\n",
    "chain_final_writer = prompt_final_writer | llm_final_writer | output_parser\n",
    "\n",
    "output_final_report = chain_final_writer.invoke({'report': output, 'feedback': feedback_output})\n",
    "\n",
    "Markdown(output_final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidhya-agents",
   "language": "python",
   "name": "vidhya-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
